{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Available functions:**\n",
    "\n",
    "`create_student_df()`: Returns merged studentInfo and studentRegistration with chosen features.\n",
    "\n",
    "`create_assessment_df()`: Returns merged assessments and studentAssessment with chosen features. Currently set to return the first two assessments from courses AAA-FFF.\n",
    "\n",
    "`wide_form_sa()`: Takes the dataframe returned by `create_assessment_df()` and returns a wide-form variant.\n",
    "\n",
    "`create_si_sa_df()`: Returns merged dataframes created by `create_student_df()` and `wide_form_sa()`.\n",
    "\n",
    "`create_vle_df()`: Returns merged vle and studentVle with chosen features. Currently set to return everything on or before day 60 (including pre-course days), binned by 15 day intervals, from courses AAA-FFF. Currently returning ONLY `forumng` activity for run speed, until we nail down which activities to focus on.\n",
    "\n",
    "`wide_form_vle()`: Takes the dataframe returned by `create_vle_df()` and returnsa  wide-form varient.\n",
    "\n",
    "`create_si_sa_vle_df()`: Returns merged dataframes created by `create_si_sa_df()` and `wide_form_vle` for a full index-features dataframe\n",
    "\n",
    "\n",
    "`assessment_namer(id_assessment)`: Helper function for `create_assessment_df()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_student_df():\n",
    "    # Read in .csv's to be joined\n",
    "    studentInfo = pd.read_csv('dataset/studentInfo.csv')\n",
    "    studentRegistration = pd.read_csv('dataset/studentRegistration.csv')\n",
    "\n",
    "    # Drop any unnecessary columns (can be edited for feature extraction)\n",
    "    si_drop_cols = ['gender', 'region', 'highest_education', 'imd_band', 'disability']\n",
    "    si = studentInfo.drop(columns=si_drop_cols)\n",
    "\n",
    "    # Merge, inner join\n",
    "    student_df = pd.merge(si, studentRegistration, how='inner', on=['code_module', 'code_presentation', 'id_student'])\n",
    "\n",
    "    return student_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assessment_namer(id_assessment):\n",
    "    Assess_1s = [1752, 1758, 14984, 14996, 15008, 15020, 24282, 24291, 25334, 25348, 25355, 25362, 30709, 30714, 30719, 34860, 34873, 34886, 34899]\n",
    "    Assess_2s = [1753, 1759, 14985, 14997, 15009, 15021, 24283, 24292, 25335, 25349, 25356, 25363, 30710, 30715, 30720, 34861, 34874, 34887, 34900]\n",
    "\n",
    "    if id_assessment in Assess_1s:\n",
    "        return \"A1\"\n",
    "    elif id_assessment in Assess_2s:\n",
    "        return \"A2\"\n",
    "    else:\n",
    "        return \"Drop\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_assessment_df():\n",
    "    # Read in .csv's to be joined\n",
    "    assessments = pd.read_csv('dataset/assessments.csv')\n",
    "    studentAssessment = pd.read_csv('dataset/studentAssessment.csv')\n",
    "\n",
    "    # Drop any unnecessary columns\n",
    "    sa_drop_cols = ['is_banked']\n",
    "    sa = studentAssessment.drop(columns=sa_drop_cols)\n",
    "\n",
    "    # Merge, left join\n",
    "    assessment_df = pd.merge(sa, assessments, how='left', on='id_assessment')\n",
    "\n",
    "    # Dropping 'assessment_type' == 'CMA' due to extreme course differences\n",
    "    # Also dropping the final exam because we want to catch students BEFORE then\n",
    "    a_filtered = assessment_df[assessment_df.assessment_type == 'TMA']\n",
    "\n",
    "    # Mapping with assessment_namer\n",
    "    a_filtered['assessment_name'] = a_filtered['id_assessment'].apply(assessment_namer)\n",
    "    a_filtered = a_filtered[a_filtered.assessment_name != 'Drop']\n",
    "    \n",
    "\n",
    "    return a_filtered\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_form_sa():\n",
    "    sa = create_assessment_df()\n",
    "\n",
    "    # Combine date submitted and date into -/+\n",
    "    sa['days_from_due'] = sa['date_submitted'] - sa['date']\n",
    "\n",
    "    # Drop Assessment Type, Weight\n",
    "    sa.drop(columns=['assessment_type', 'weight', 'date_submitted', 'date', 'id_assessment'], inplace=True)\n",
    "\n",
    "    inds = ['id_student', 'code_module', 'code_presentation']\n",
    "    vals = ['score', 'days_from_due']\n",
    "\n",
    "    sa_wide = sa.pivot_table(\n",
    "                values = vals,\n",
    "                columns = 'assessment_name',\n",
    "                index = inds\n",
    "    )\n",
    "\n",
    "    \n",
    "    sa_wide.columns = [\"_\".join(a) for a in sa_wide.columns.to_flat_index()]\n",
    "    sa_wide.reset_index(inplace=True)\n",
    "\n",
    "    return sa_wide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_si_sa_df():\n",
    "    si = create_student_df()\n",
    "    sa = wide_form_sa()\n",
    "\n",
    "    # Merge\n",
    "    si_sa_df = pd.merge(si, sa, how='inner', on=['code_module', 'code_presentation', 'id_student'])\n",
    "\n",
    "    return si_sa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vle_df():\n",
    "    studentVle = pd.read_csv('dataset/studentVle.csv')\n",
    "    vle = pd.read_csv('dataset/vle.csv')\n",
    "\n",
    "    # Dropping unused columns from raw\n",
    "    vle.drop(columns=['week_from', 'week_to'], inplace=True)\n",
    "\n",
    "    #Merge - this primarily associates 'id_site' with a more narrative description\n",
    "    vle_merged = pd.merge(studentVle, vle, how='left', on=['code_module', 'code_presentation', 'id_site'])\n",
    "    vle_merged.drop(columns='id_site', inplace=True)\n",
    "\n",
    "    # Dropping GGG\n",
    "    vle_no_ggg = vle_merged[vle_merged.code_module != 'GGG']\n",
    "\n",
    "    # Dropping activity types we're less interested in\n",
    "    # For now, I'm only using 'forumng' for testing purposes\n",
    "    # EDIT 07/19/2022, running without this to make a biiiig xlsx so we can see what's most important\n",
    "    #vle_subset = vle_no_ggg[vle_no_ggg.activity_type == 'forumng']\n",
    "    vle_subset = vle_no_ggg\n",
    "\n",
    "    # Dropping after certain date (Adjust as desired!)\n",
    "    date_max = 60\n",
    "    vle_df = vle_subset[vle_subset.date <= date_max]\n",
    "\n",
    "    # Creating bin columns\n",
    "    # Set bin parameters (Also adjust as desired!)\n",
    "    bin_vals = [-15, 0, 15, 30, 45, 60]\n",
    "    bin_labels = ['pre-0', '1-15', '16-30', '31-45', '46-60']\n",
    "    vle_df['bin'] = pd.cut(vle_df['date'], bins=bin_vals, labels=bin_labels)\n",
    "    vle_df.drop(columns='date', inplace=True)\n",
    "\n",
    "    # Groupby everything but sum_click\n",
    "    grouper = ['code_module', 'code_presentation', 'id_student', 'activity_type', 'bin']\n",
    "    vle_df_grouped = vle_df.groupby(grouper)['sum_click'].sum().to_frame()\n",
    "    vle_df_grouped.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "    return vle_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_form_vle():\n",
    "    vle_df_long = create_vle_df()\n",
    "    vle_df_wide = vle_df_long.pivot_table(\n",
    "                values = 'sum_click',\n",
    "                columns = ['activity_type', 'bin'],\n",
    "                index = ['id_student', 'code_module', 'code_presentation']\n",
    "    )\n",
    "\n",
    "    vle_df_wide.columns = [\"_\".join(a) for a in vle_df_wide.columns.to_flat_index()]\n",
    "    vle_df_wide.reset_index(inplace=True)\n",
    "\n",
    "    return vle_df_wide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_si_sa_vle_df():\n",
    "    si_sa_df = create_si_sa_df()\n",
    "    vle = wide_form_vle()\n",
    "\n",
    "    # Merge\n",
    "    si_sa_vle_df = pd.merge(si_sa_df, vle, how='inner', on=['code_module', 'code_presentation', 'id_student'])\n",
    "\n",
    "    return si_sa_vle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df = create_si_sa_vle_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to create xlsx on local machine if not pulling from github\n",
    "#wide_df.to_excel(\"wideform.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('py3env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5ea06c7a26b0a568b20218ec0dd2c45580d247d57affd213d61a81137fa7306"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
