{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Available functions:**\n",
    "\n",
    "`create_student_df()`: Returns merged studentInfo and studentRegistration with chosen features.\n",
    "\n",
    "`create_assessment_df()`: Returns merged assessments and studentAssessment with chosen features. Currently set to return the first two assessments from courses AAA-FFF.\n",
    "\n",
    "`wide_form_sa()`: Takes the dataframe returned by `create_assessment_df()` and returns a wide-form variant.\n",
    "\n",
    "`create_si_sa_df()`: Returns merged dataframes created by `create_student_df()` and `wide_form_sa()`.\n",
    "\n",
    "`create_vle_df()`: Returns merged vle and studentVle with chosen features. Currently set to return everything on or before day 60 (including pre-course days), binned by 15 day intervals, from courses AAA-FFF.\n",
    "\n",
    "`wide_form_vle()`: Takes the dataframe returned by `create_vle_df()` and returnsa  wide-form varient.\n",
    "\n",
    "`create_si_sa_vle_df()`: Returns merged dataframes created by `create_si_sa_df()` and `wide_form_vle` for a full index-features dataframe\n",
    "\n",
    "\n",
    "`assessment_namer(id_assessment)`: Helper function for `create_assessment_df()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_student_df():\n",
    "    # Read in .csv's to be joined\n",
    "    studentInfo = pd.read_csv('dataset/studentInfo.csv')\n",
    "    studentRegistration = pd.read_csv('dataset/studentRegistration.csv')\n",
    "\n",
    "    # Drop any unnecessary columns (can be edited for feature extraction)\n",
    "    si_drop_cols = ['gender', 'region', 'highest_education', 'imd_band', 'disability']\n",
    "    si = studentInfo.drop(columns=si_drop_cols)\n",
    "\n",
    "    # Merge, inner join\n",
    "    student_df = pd.merge(si, studentRegistration, how='inner', on=['code_module', 'code_presentation', 'id_student'])\n",
    "\n",
    "    return student_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assessment_namer(id_assessment):\n",
    "    Assess_1s = [1752, 1758, 14984, 14996, 15008, 15020, 24282, 24291, 25334, 25348, 25355, 25362, 30709, 30714, 30719, 34860, 34873, 34886, 34899]\n",
    "    Assess_2s = [1753, 1759, 14985, 14997, 15009, 15021, 24283, 24292, 25335, 25349, 25356, 25363, 30710, 30715, 30720, 34861, 34874, 34887, 34900]\n",
    "\n",
    "    if id_assessment in Assess_1s:\n",
    "        return \"A1\"\n",
    "    elif id_assessment in Assess_2s:\n",
    "        return \"A2\"\n",
    "    else:\n",
    "        return \"Drop\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_assessment_df():\n",
    "    # Read in .csv's to be joined\n",
    "    assessments = pd.read_csv('dataset/assessments.csv')\n",
    "    studentAssessment = pd.read_csv('dataset/studentAssessment.csv')\n",
    "\n",
    "    # Drop any unnecessary columns\n",
    "    sa_drop_cols = ['is_banked']\n",
    "    sa = studentAssessment.drop(columns=sa_drop_cols)\n",
    "\n",
    "    # Merge, left join\n",
    "    assessment_df = pd.merge(sa, assessments, how='left', on='id_assessment')\n",
    "\n",
    "    # Dropping 'assessment_type' == 'CMA' due to extreme course differences\n",
    "    # Also dropping the final exam because we want to catch students BEFORE then\n",
    "    a_filtered = assessment_df[assessment_df.assessment_type == 'TMA']\n",
    "\n",
    "    # Mapping with assessment_namer\n",
    "    a_filtered['assessment_name'] = a_filtered['id_assessment'].apply(assessment_namer)\n",
    "    a_filtered = a_filtered[a_filtered.assessment_name != 'Drop']\n",
    "    \n",
    "\n",
    "    return a_filtered\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_form_sa():\n",
    "    sa = create_assessment_df()\n",
    "\n",
    "    # Combine date submitted and date into -/+\n",
    "    sa['days_from_due'] = sa['date_submitted'] - sa['date']\n",
    "\n",
    "    # Drop Assessment Type, Weight\n",
    "    sa.drop(columns=['assessment_type', 'weight', 'date_submitted', 'date', 'id_assessment'], inplace=True)\n",
    "\n",
    "    inds = ['id_student', 'code_module', 'code_presentation']\n",
    "    vals = ['score', 'days_from_due']\n",
    "\n",
    "    sa_wide = sa.pivot_table(\n",
    "                values = vals,\n",
    "                columns = 'assessment_name',\n",
    "                index = inds\n",
    "    )\n",
    "\n",
    "    \n",
    "    sa_wide.columns = [\"_\".join(a) for a in sa_wide.columns.to_flat_index()]\n",
    "    sa_wide.reset_index(inplace=True)\n",
    "\n",
    "    return sa_wide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_si_sa_df():\n",
    "    si = create_student_df()\n",
    "    sa = wide_form_sa()\n",
    "\n",
    "    # Merge\n",
    "    si_sa_df = pd.merge(si, sa, how='inner', on=['code_module', 'code_presentation', 'id_student'])\n",
    "\n",
    "    return si_sa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vle_df():\n",
    "    studentVle = pd.read_csv('dataset/studentVle.csv')\n",
    "    vle = pd.read_csv('dataset/vle.csv')\n",
    "\n",
    "    # Dropping unused columns from raw\n",
    "    vle.drop(columns=['week_from', 'week_to'], inplace=True)\n",
    "\n",
    "    #Merge - this primarily associates 'id_site' with a more narrative description\n",
    "    vle_merged = pd.merge(studentVle, vle, how='left', on=['code_module', 'code_presentation', 'id_site'])\n",
    "    vle_merged.drop(columns='id_site', inplace=True)\n",
    "\n",
    "    # Dropping GGG\n",
    "    vle_no_ggg = vle_merged[vle_merged.code_module != 'GGG']\n",
    "\n",
    "    # Dropping activity types we're less interested in\n",
    "    # For now, I'm only using 'forumng' for testing purposes\n",
    "    # EDIT 07/19/2022, running without this to make a biiiig xlsx so we can see what's most important\n",
    "    #vle_subset = vle_no_ggg[vle_no_ggg.activity_type == 'forumng']\n",
    "    vle_subset = vle_no_ggg\n",
    "\n",
    "    # Dropping after certain date (Adjust as desired!)\n",
    "    date_max = 60\n",
    "    vle_df = vle_subset[vle_subset.date <= date_max]\n",
    "\n",
    "    # Creating bin columns\n",
    "    # Set bin parameters (Also adjust as desired!)\n",
    "    bin_vals = [-15, 0, 15, 30, 45, 60]\n",
    "    bin_labels = ['pre-0', '1-15', '16-30', '31-45', '46-60']\n",
    "    vle_df['bin'] = pd.cut(vle_df['date'], bins=bin_vals, labels=bin_labels)\n",
    "    vle_df.drop(columns='date', inplace=True)\n",
    "\n",
    "    # Groupby everything but sum_click\n",
    "    grouper = ['code_module', 'code_presentation', 'id_student', 'activity_type', 'bin']\n",
    "    vle_df_grouped = vle_df.groupby(grouper)['sum_click'].sum().to_frame()\n",
    "    vle_df_grouped.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "    return vle_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_form_vle():\n",
    "    vle_df_long = create_vle_df()\n",
    "    vle_df_wide = vle_df_long.pivot_table(\n",
    "                values = 'sum_click',\n",
    "                columns = ['activity_type', 'bin'],\n",
    "                index = ['id_student', 'code_module', 'code_presentation']\n",
    "    )\n",
    "\n",
    "    vle_df_wide.columns = [\"_\".join(a) for a in vle_df_wide.columns.to_flat_index()]\n",
    "    vle_df_wide.reset_index(inplace=True)\n",
    "\n",
    "    return vle_df_wide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_si_sa_vle_df():\n",
    "    si_sa_df = create_si_sa_df()\n",
    "    vle = wide_form_vle()\n",
    "\n",
    "    # Merge\n",
    "    si_sa_vle_df = pd.merge(si_sa_df, vle, how='inner', on=['code_module', 'code_presentation', 'id_student'])\n",
    "\n",
    "    return si_sa_vle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wide_df = create_si_sa_vle_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to create xlsx on local machine if not pulling from github\n",
    "#wide_df.to_excel(\"wideform.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vle_df_v2(code_module,code_presentation):\n",
    "    studentVle = pd.read_csv('dataset/studentVle.csv')\n",
    "    vle = pd.read_csv('dataset/vle.csv')\n",
    "\n",
    "    # Dropping unused columns from raw\n",
    "    vle.drop(columns=['week_from', 'week_to'], inplace=True)\n",
    "\n",
    "    #Merge - this primarily associates 'id_site' with a more narrative description\n",
    "    vle_merged = pd.merge(studentVle, vle, how='left', on=['code_module', 'code_presentation', 'id_site'])\n",
    "    vle_merged.drop(columns='id_site', inplace=True)\n",
    "\n",
    "    # For this one, we're lumping all activity_types together.\n",
    "    vle_merged.drop(columns='activity_type', inplace=True)\n",
    "\n",
    "    # Only using AAA\n",
    "    vle_aaa = vle_merged[vle_merged.code_module == code_module]\n",
    "    #and only using 2014J\n",
    "    vle_section = vle_aaa[vle_aaa.code_presentation == code_presentation]\n",
    "\n",
    "    \n",
    "    # Groupby everything but sum_click\n",
    "    grouper = ['code_module', 'code_presentation', 'id_student', 'date']\n",
    "    vle_df_grouped = vle_section.groupby(grouper)['sum_click'].sum().to_frame()\n",
    "    vle_df_grouped.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "    return vle_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_form_sa_v2(code_module, code_presentation):\n",
    "    sa = create_assessment_df()\n",
    "\n",
    "    # Drop Assessment Type, Weight\n",
    "    sa.drop(columns=['assessment_type', 'weight', 'date', 'id_assessment'], inplace=True)\n",
    "\n",
    "    inds = ['id_student', 'code_module', 'code_presentation']\n",
    "    vals = ['score', 'date_submitted']\n",
    "\n",
    "    sa_wide = sa.pivot_table(\n",
    "                values = vals,\n",
    "                columns = 'assessment_name',\n",
    "                index = inds\n",
    "    )\n",
    "\n",
    "    \n",
    "    sa_wide.columns = [\"_\".join(a) for a in sa_wide.columns.to_flat_index()]\n",
    "    sa_wide.reset_index(inplace=True)\n",
    "\n",
    "    # Only using AAA\n",
    "    sa_aaa = sa_wide[sa_wide.code_module == code_module]\n",
    "    # And, just in case there are duplicates of id_student,\n",
    "    sa_section = sa_aaa[sa_aaa.code_presentation == code_presentation]\n",
    "\n",
    "\n",
    "\n",
    "    return sa_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_submission_bins():\n",
    "    full_df = create_si_sa_vle_df()\n",
    "\n",
    "    modules = full_df['code_module'].unique()\n",
    "    presentations = full_df['code_presentation'].unique()\n",
    "\n",
    "    binned_df = pd.DataFrame(columns=['id_student','code_module', 'code_presentation', 'sum_click_pre_A1', 'sum_click_pre_A2'])\n",
    "\n",
    "    for m in modules:\n",
    "        for p in presentations:\n",
    "            sa_df = wide_form_sa_v2(m, p)\n",
    "            vle_df = create_vle_df_v2(m, p)\n",
    "\n",
    "        # Dropping any students that didn't turn in one or more assignments\n",
    "        sa_df.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "        A1_submit = sa_df.set_index('id_student').to_dict()['date_submitted_A1']\n",
    "        A2_submit = sa_df.set_index('id_student').to_dict()['date_submitted_A2']\n",
    "\n",
    "        vle_df['date_submitted_A1'] = vle_df['id_student'].map(A1_submit)\n",
    "        vle_df['date_submitted_A2'] = vle_df['id_student'].map(A2_submit)\n",
    "\n",
    "\n",
    "        vle_df['bin'] = 2\n",
    "        vle_df.loc[vle_df['date'] < vle_df['date_submitted_A2'], 'bin'] = 'pre_A2'\n",
    "        vle_df.loc[vle_df['date'] < vle_df['date_submitted_A1'], 'bin'] = 'pre_A1'\n",
    "\n",
    "        vle_df.dropna(axis=0, how='any', inplace=True)\n",
    "        before_A2 = vle_df[vle_df.bin != 2]\n",
    "\n",
    "        before_A2.drop(columns=['date_submitted_A1', 'date_submitted_A2'], inplace=True)\n",
    "\n",
    "        # Groupby\n",
    "        grouper = ['code_module', 'code_presentation', 'id_student', 'bin']\n",
    "        vle_df_grouped = before_A2.groupby(grouper)['sum_click'].sum().to_frame()\n",
    "        vle_df_grouped.reset_index(inplace=True)\n",
    "\n",
    "        inds = ['id_student', 'code_module', 'code_presentation']\n",
    "        vals = ['sum_click']\n",
    "\n",
    "        df_wide = vle_df_grouped.pivot_table(\n",
    "                    values = vals,\n",
    "                    columns = 'bin',\n",
    "                    index = inds\n",
    "        )\n",
    "\n",
    "        df_wide.columns = [\"_\".join(a) for a in df_wide.columns.to_flat_index()]\n",
    "        df_wide.reset_index(inplace=True)\n",
    "\n",
    "        binned_df = pd.concat([binned_df, df_wide], ignore_index=True)\n",
    "\n",
    "    even_fuller_df =  pd.merge(full_df, binned_df, how='inner', on=['code_module', 'code_presentation', 'id_student'])\n",
    "\n",
    "    return even_fuller_df\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_module</th>\n",
       "      <th>code_presentation</th>\n",
       "      <th>id_student</th>\n",
       "      <th>age_band</th>\n",
       "      <th>num_of_prev_attempts</th>\n",
       "      <th>studied_credits</th>\n",
       "      <th>final_result</th>\n",
       "      <th>date_registration</th>\n",
       "      <th>date_unregistration</th>\n",
       "      <th>days_from_due_A1</th>\n",
       "      <th>...</th>\n",
       "      <th>subpage_16-30</th>\n",
       "      <th>subpage_31-45</th>\n",
       "      <th>subpage_46-60</th>\n",
       "      <th>url_pre-0</th>\n",
       "      <th>url_1-15</th>\n",
       "      <th>url_16-30</th>\n",
       "      <th>url_31-45</th>\n",
       "      <th>url_46-60</th>\n",
       "      <th>sum_click_pre_A1</th>\n",
       "      <th>sum_click_pre_A2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBB</td>\n",
       "      <td>2014B</td>\n",
       "      <td>50069</td>\n",
       "      <td>0-35</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>Fail</td>\n",
       "      <td>-134.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BBB</td>\n",
       "      <td>2014B</td>\n",
       "      <td>52426</td>\n",
       "      <td>35-55</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>Fail</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BBB</td>\n",
       "      <td>2014B</td>\n",
       "      <td>55968</td>\n",
       "      <td>0-35</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>Fail</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BBB</td>\n",
       "      <td>2014B</td>\n",
       "      <td>59725</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>Distinction</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>184.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BBB</td>\n",
       "      <td>2014B</td>\n",
       "      <td>60416</td>\n",
       "      <td>0-35</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>Pass</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>697.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  code_module code_presentation id_student age_band  num_of_prev_attempts  \\\n",
       "0         BBB             2014B      50069     0-35                     0   \n",
       "1         BBB             2014B      52426    35-55                     1   \n",
       "2         BBB             2014B      55968     0-35                     0   \n",
       "3         BBB             2014B      59725    35-55                     0   \n",
       "4         BBB             2014B      60416     0-35                     1   \n",
       "\n",
       "   studied_credits final_result  date_registration  date_unregistration  \\\n",
       "0               90         Fail             -134.0                  NaN   \n",
       "1               60         Fail              -32.0                  NaN   \n",
       "2              120         Fail              -29.0                  NaN   \n",
       "3              120  Distinction              -29.0                  NaN   \n",
       "4               60         Pass              -64.0                  NaN   \n",
       "\n",
       "   days_from_due_A1  ...  subpage_16-30  subpage_31-45  subpage_46-60  \\\n",
       "0              -1.0  ...            NaN            NaN           21.0   \n",
       "1              -3.0  ...            2.0            NaN            NaN   \n",
       "2              -2.0  ...            NaN            4.0            5.0   \n",
       "3              -3.0  ...            4.0            NaN            NaN   \n",
       "4              -5.0  ...            1.0            3.0            1.0   \n",
       "\n",
       "   url_pre-0  url_1-15  url_16-30  url_31-45  url_46-60  sum_click_pre_A1  \\\n",
       "0        NaN       2.0        NaN        NaN        5.0              54.0   \n",
       "1        NaN       3.0        NaN        NaN        NaN              26.0   \n",
       "2        1.0       NaN        NaN        3.0        1.0             133.0   \n",
       "3        6.0       4.0        NaN        NaN        NaN             184.0   \n",
       "4        2.0       1.0        1.0        4.0        3.0             125.0   \n",
       "\n",
       "   sum_click_pre_A2  \n",
       "0              99.0  \n",
       "1              16.0  \n",
       "2             248.0  \n",
       "3              82.0  \n",
       "4             697.0  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# THIS TAKES 20 MINUTES\n",
    "\n",
    "#really_big_df = add_submission_bins()\n",
    "#really_big_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#really_big_df.to_excel(\"wideform.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('py3env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5ea06c7a26b0a568b20218ec0dd2c45580d247d57affd213d61a81137fa7306"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
