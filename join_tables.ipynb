{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Available functions:**\n",
    "\n",
    "`create_student_df()`: Returns merged studentInfo and studentRegistration with chosen features. Please see dictionaries for map values.\n",
    "\n",
    "`assessment_namer(id_assessment)`: Helper function for `create_assessment_df()`\n",
    "\n",
    "`create_assessment_df()`: Returns merged assessments and studentAssessment with chosen features. Currently set to return the first two assessments from courses AAA-FFF.\n",
    "\n",
    "`wide_form_sa()`: Takes the dataframe returned by `create_assessment_df()` and returns a wide-form variant.\n",
    "\n",
    "`create_si_sa_df()`: Returns merged dataframes created by `create_student_df()` and `wide_form_sa()`.\n",
    "\n",
    "`create_vle_df()`: Returns merged vle and studentVle with chosen features. Currently set to return everything on or before day 60 (including pre-course days), binned by 15 day intervals, from courses AAA-FFF.\n",
    "\n",
    "`wide_form_vle()`: Takes the dataframe returned by `create_vle_df()` and returns a wide-form varient.\n",
    "\n",
    "`create_si_sa_vle_df()`: Returns merged dataframes created by `create_si_sa_df()` and `wide_form_vle` \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_student_df():\n",
    "    # Read in .csv's to be joined\n",
    "    studentInfo = pd.read_csv('dataset/studentInfo.csv')\n",
    "    studentRegistration = pd.read_csv('dataset/studentRegistration.csv')\n",
    "\n",
    "    gender_map = {'M': 0, 'F': 1}\n",
    "    ed_map = {'No Formal quals': 0, 'Lower Than A Level': 1, 'A Level or Equivalent': 2, 'HE Qualification': 3, 'Post Graduate Qualification': 4}\n",
    "    disability_map = {'N': 0, 'Y': 1}\n",
    "    age_map = {'0-35': 0, '35-55': 1, '55<=': 2}\n",
    "    result_map = {'Pass': 0, 'Distinction': 0, 'Fail': 1, 'Withdrawn': 2}\n",
    "\n",
    "    studentInfo[\"gender\"]=studentInfo['gender'].map(gender_map)\n",
    "    studentInfo[\"highest_education\"]=studentInfo['highest_education'].map(ed_map)\n",
    "    studentInfo[\"disability\"]=studentInfo['disability'].map(disability_map)\n",
    "    studentInfo[\"age_band\"]=studentInfo['age_band'].map(age_map)\n",
    "    studentInfo[\"final_result\"]=studentInfo['final_result'].map(result_map)\n",
    "    \n",
    "\n",
    "    # Drop any unnecessary columns (can be edited for feature extraction)\n",
    "    si_drop_cols = ['region','imd_band']\n",
    "    si = studentInfo.drop(columns=si_drop_cols) \n",
    "\n",
    "    # Merge, inner join\n",
    "    student_df = pd.merge(si, studentRegistration, how='inner', on=['code_module', 'code_presentation', 'id_student'])\n",
    "\n",
    "    return student_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assessment_namer(id_assessment):\n",
    "    Assess_1s = [1752, 1758, 14984, 14996, 15008, 15020, 24282, 24291, 25334, 25348, 25355, 25362, 30709, 30714, 30719, 34860, 34873, 34886, 34899]\n",
    "    Assess_2s = [1753, 1759, 14985, 14997, 15009, 15021, 24283, 24292, 25335, 25349, 25356, 25363, 30710, 30715, 30720, 34861, 34874, 34887, 34900]\n",
    "\n",
    "    if id_assessment in Assess_1s:\n",
    "        return \"A1\"\n",
    "    elif id_assessment in Assess_2s:\n",
    "        return \"A2\"\n",
    "    else:\n",
    "        return \"Drop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_assessment_df():\n",
    "    # Read in .csv's to be joined\n",
    "    assessments = pd.read_csv('dataset/assessments.csv')\n",
    "    studentAssessment = pd.read_csv('dataset/studentAssessment.csv')\n",
    "\n",
    "    # Drop any unnecessary columns\n",
    "    sa_drop_cols = ['is_banked']\n",
    "    sa = studentAssessment.drop(columns=sa_drop_cols)\n",
    "\n",
    "    # Merge, left join\n",
    "    assessment_df = pd.merge(sa, assessments, how='left', on='id_assessment')\n",
    "\n",
    "    # Dropping 'assessment_type' == 'CMA' due to extreme course differences\n",
    "    # Also dropping the final exam because we want to catch students BEFORE then\n",
    "    a_filtered = assessment_df[assessment_df.assessment_type == 'TMA']\n",
    "\n",
    "    # Mapping with assessment_namer\n",
    "    a_filtered['assessment_name'] = a_filtered['id_assessment'].apply(assessment_namer)\n",
    "    a_filtered = a_filtered[a_filtered.assessment_name != 'Drop']\n",
    "\n",
    "    # Add weighted score column\n",
    "    a_filtered['weighted_score'] = a_filtered['score'] * a_filtered['weight'] / 100\n",
    "    # Combine date submitted and date into -/+\n",
    "    a_filtered['days_from_due'] = a_filtered['date_submitted'] - a_filtered['date']\n",
    "    \n",
    "\n",
    "    return a_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_form_sa():\n",
    "    sa = create_assessment_df()\n",
    "\n",
    "    # Drop Assessment Type, Weight\n",
    "    sa.drop(columns=['assessment_type', 'weight', 'date', 'id_assessment'], inplace=True)\n",
    "\n",
    "    inds = ['id_student', 'code_module', 'code_presentation']\n",
    "    vals = ['score', 'weighted_score', 'days_from_due', 'date_submitted']\n",
    "\n",
    "    sa_wide = sa.pivot_table(\n",
    "                values = vals,\n",
    "                columns = 'assessment_name',\n",
    "                index = inds\n",
    "    )\n",
    "    \n",
    "    sa_wide.columns = [\"_\".join(a) for a in sa_wide.columns.to_flat_index()]\n",
    "    sa_wide.reset_index(inplace=True)\n",
    "\n",
    "    sa_wide['score_A1'] = sa_wide['score_A1'].fillna(0)\n",
    "    sa_wide['score_A2'] = sa_wide['score_A2'].fillna(0)\n",
    "    sa_wide['weighted_score_A1'] = sa_wide['weighted_score_A1'].fillna(0)\n",
    "    sa_wide['weighted_score_A2'] = sa_wide['weighted_score_A2'].fillna(0)\n",
    "    sa_wide['days_from_due_A1'] = sa_wide['days_from_due_A1'].fillna(999)\n",
    "    sa_wide['days_from_due_A2'] = sa_wide['days_from_due_A2'].fillna(999)\n",
    "    sa_wide['date_submitted_A1'] = sa_wide['date_submitted_A1'].fillna(999)\n",
    "    sa_wide['date_submitted_A2'] = sa_wide['date_submitted_A2'].fillna(999)\n",
    "\n",
    "\n",
    "\n",
    "    return sa_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_si_sa_df():\n",
    "    si = create_student_df()\n",
    "    sa = wide_form_sa()\n",
    "\n",
    "    # Merge\n",
    "    si_sa_df = pd.merge(si, sa, how='inner', on=['code_module', 'code_presentation', 'id_student'])\n",
    "\n",
    "    return si_sa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vle_df():\n",
    "    studentVle = pd.read_csv('dataset/studentVle.csv')\n",
    "    vle = pd.read_csv('dataset/vle.csv')\n",
    "\n",
    "    # Dropping unused columns from raw\n",
    "    vle.drop(columns=['week_from', 'week_to'], inplace=True)\n",
    "\n",
    "    #Merge - this primarily associates 'id_site' with a more narrative description\n",
    "    vle_merged = pd.merge(studentVle, vle, how='left', on=['code_module', 'code_presentation', 'id_site'])\n",
    "    vle_merged.drop(columns='id_site', inplace=True)\n",
    "\n",
    "    # Dropping GGG\n",
    "    vle_subset = vle_merged[vle_merged.code_module != 'GGG']\n",
    "\n",
    "    # Dropping after certain date (Adjust as desired!)\n",
    "    date_max = 60\n",
    "    vle_df = vle_subset[vle_subset.date <= date_max]\n",
    "\n",
    "    # Creating bin columns\n",
    "    # Set bin parameters (Also adjust as desired!)\n",
    "    bin_vals = [-15, 0, 15, 30, 45, 60]\n",
    "    bin_labels = ['pre-0', '1-15', '16-30', '31-45', '46-60']\n",
    "    vle_df['bin'] = pd.cut(vle_df['date'], bins=bin_vals, labels=bin_labels)\n",
    "    vle_df.drop(columns='date', inplace=True)\n",
    "\n",
    "    # Groupby everything but sum_click\n",
    "    grouper = ['code_module', 'code_presentation', 'id_student', 'activity_type', 'bin']\n",
    "    vle_df_grouped = vle_df.groupby(grouper)['sum_click'].sum().to_frame()\n",
    "    vle_df_grouped.reset_index(inplace=True)\n",
    "\n",
    "    vle_df_grouped['sum_click'] = vle_df_grouped['sum_click'].fillna(0)\n",
    "\n",
    "\n",
    "    return vle_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_form_vle():\n",
    "    vle_df_long = create_vle_df()\n",
    "    vle_df_wide = vle_df_long.pivot_table(\n",
    "                values = 'sum_click',\n",
    "                columns = ['activity_type', 'bin'],\n",
    "                index = ['id_student', 'code_module', 'code_presentation']\n",
    "    )\n",
    "\n",
    "    vle_df_wide.columns = [\"_\".join(a) for a in vle_df_wide.columns.to_flat_index()]\n",
    "    vle_df_wide.reset_index(inplace=True)\n",
    "\n",
    "    return vle_df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_si_sa_vle_df():\n",
    "    si_sa_df = create_si_sa_df()\n",
    "    vle = wide_form_vle()\n",
    "\n",
    "    # Merge\n",
    "    si_sa_vle_df = pd.merge(si_sa_df, vle, how='inner', on=['code_module', 'code_presentation', 'id_student'])\n",
    "\n",
    "    return si_sa_vle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vle_df_filtered(code_module,code_presentation):\n",
    "    studentVle = pd.read_csv('dataset/studentVle.csv')\n",
    "    vle = pd.read_csv('dataset/vle.csv')\n",
    "\n",
    "    # Prepping Vle info\n",
    "    # Dropping unused columns from raw vle\n",
    "    vle.drop(columns=['week_from', 'week_to'], inplace=True)\n",
    "\n",
    "    #Merge - this primarily associates 'id_site' with a more narrative description\n",
    "    vle_merged = pd.merge(studentVle, vle, how='left', on=['code_module', 'code_presentation', 'id_site'])\n",
    "    vle_merged.drop(columns='id_site', inplace=True)\n",
    "\n",
    "    # For this one, we're lumping all activity_types together.\n",
    "    vle_merged.drop(columns='activity_type', inplace=True)\n",
    "\n",
    "    # Filter by module\n",
    "    vle_subset1 = vle_merged[vle_merged.code_module == code_module]\n",
    "    # Filter by presentation (semester)\n",
    "    vle_subset2 = vle_subset1[vle_subset1.code_presentation == code_presentation]\n",
    "\n",
    "    # Groupby everything but sum_click\n",
    "    grouper = ['code_module', 'code_presentation', 'id_student', 'date']\n",
    "    vle_df_grouped = vle_subset2.groupby(grouper)['sum_click'].sum().to_frame()\n",
    "    vle_df_grouped.reset_index(inplace=True)\n",
    "\n",
    "    return vle_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_form_sa_filtered(code_module, code_presentation):\n",
    "    sa_wide = wide_form_sa()\n",
    "\n",
    "    # Filter by module\n",
    "    sa_subset1 = sa_wide[sa_wide.code_module == code_module]\n",
    "    # Filter by presentation (semester)\n",
    "    sa_subset2 = sa_subset1[sa_subset1.code_presentation == code_presentation]\n",
    "\n",
    "    return sa_subset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_df = create_si_sa_vle_df()\n",
    "#full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_submission_bins(full_df):\n",
    "    #full_df = create_si_sa_vle_df()\n",
    "\n",
    "    modules = full_df['code_module'].unique()\n",
    "    presentations = full_df['code_presentation'].unique()\n",
    "\n",
    "    binned_df = pd.DataFrame(columns=['id_student','code_module', 'code_presentation', 'sum_click_pre_A1', 'sum_click_pre_A2'])\n",
    "\n",
    "    for m in modules:\n",
    "        for p in presentations:\n",
    "            sa_df = wide_form_sa_filtered(m, p)\n",
    "            vle_df = create_vle_df_filtered(m, p)\n",
    "\n",
    "            A1_submit = sa_df.set_index('id_student').to_dict()['date_submitted_A1']\n",
    "            A2_submit = sa_df.set_index('id_student').to_dict()['date_submitted_A2']\n",
    "            \n",
    "\n",
    "        \n",
    "            vle_df['date_submitted_A1'] = vle_df['id_student'].map(A1_submit)\n",
    "            vle_df['date_submitted_A2'] = vle_df['id_student'].map(A2_submit)\n",
    "\n",
    "            vle_df['bin'] = 2\n",
    "\n",
    "            vle_df.loc[vle_df['date'] < vle_df['date_submitted_A2'], 'bin'] = 'pre_A2'\n",
    "            vle_df.loc[vle_df['date'] < vle_df['date_submitted_A1'], 'bin'] = 'pre_A1'\n",
    "\n",
    "            vle_df.fillna(0)\n",
    "            before_A2 = vle_df[vle_df.bin != 2]\n",
    "\n",
    "            before_A2.drop(columns=['date_submitted_A1', 'date_submitted_A2'], inplace=True)\n",
    "\n",
    "            # Groupby\n",
    "            grouper = ['code_module', 'code_presentation', 'id_student', 'bin']\n",
    "            vle_df_grouped = before_A2.groupby(grouper)['sum_click'].sum().to_frame()\n",
    "            vle_df_grouped.reset_index(inplace=True)\n",
    "\n",
    "            inds = ['id_student', 'code_module', 'code_presentation']\n",
    "            vals = ['sum_click']\n",
    "\n",
    "            df_wide = vle_df_grouped.pivot_table(\n",
    "                        values = vals,\n",
    "                        columns = 'bin',\n",
    "                        index = inds\n",
    "            )\n",
    "\n",
    "            df_wide.columns = [\"_\".join(a) for a in df_wide.columns.to_flat_index()]\n",
    "            df_wide.reset_index(inplace=True)\n",
    "\n",
    "            binned_df = pd.concat([binned_df, df_wide], ignore_index=True)\n",
    "\n",
    "    even_fuller_df =  pd.merge(full_df, binned_df, how='left', on=['code_module', 'code_presentation', 'id_student'])\n",
    "    even_fuller_df['sum_click_pre_A1'] = even_fuller_df['sum_click_pre_A1'].fillna(0)\n",
    "    even_fuller_df['sum_click_pre_A2'] = even_fuller_df['sum_click_pre_A2'].fillna(0)\n",
    "\n",
    "    return even_fuller_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#really_big_df = add_submission_bins(full_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#really_big_df.to_excel(\"wideform.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('py3env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5ea06c7a26b0a568b20218ec0dd2c45580d247d57affd213d61a81137fa7306"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
